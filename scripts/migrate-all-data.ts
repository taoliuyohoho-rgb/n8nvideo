import { PrismaClient } from '@prisma/client'
import { execSync } from 'child_process'

const postgresDb = new PrismaClient()

async function migrateAllData() {
  console.log('ðŸš€ å¼€å§‹å®Œæ•´æ•°æ®è¿ç§»...\n')
  
  try {
    // èŽ·å–æ‰€æœ‰è¡¨å
    const tables = [
      'users',
      'products',
      'videos',
      'templates',
      'styles',
      'product_mappings',
      'product_pain_points',
      'estimation_models',
      'estimation_decisions',
      'estimation_candidates',
      'estimation_candidate_sets',
      'estimation_feedback_events',
      'estimation_outcomes',
      'reco_decisions',
      'reco_candidates',
      'reco_candidate_sets',
      'reco_feedback',
      'reco_events',
      'reco_outcomes',
      'recommendation_settings',
      'prompt_templates',
      'competitor_analyses',
      'video_analyses',
      'template_analyses',
      'reference_videos',
      'ranking_results',
      'ad_data',
      'comment_scraping_tasks',
      'product_comments',
      'user_submissions',
      'entity_embeddings',
      'entity_features',
      'entity_metrics_daily',
      'entity_index'
    ]
    
    let totalMigrated = 0
    
    for (const table of tables) {
      try {
        console.log(`\nðŸ“¦ è¿ç§»è¡¨: ${table}`)
        
        // ä»Ž SQLite å¯¼å‡ºæ•°æ®
        const jsonData = execSync(
          `sqlite3 -json ./prisma/dev.db "SELECT * FROM ${table}"`,
          { encoding: 'utf-8', cwd: '/Users/liutao/cursor/n8nvideo' }
        )
        
        const rows = JSON.parse(jsonData || '[]')
        
        if (rows.length === 0) {
          console.log(`  âš ï¸  è¡¨ ${table} ä¸ºç©ºï¼Œè·³è¿‡`)
          continue
        }
        
        console.log(`  æ‰¾åˆ° ${rows.length} æ¡è®°å½•`)
        
        // æ ¹æ®è¡¨åæ‰§è¡Œä¸åŒçš„è¿ç§»é€»è¾‘
        if (table === 'products') {
          await migrateProducts(rows)
        } else {
          // å…¶ä»–è¡¨ä½¿ç”¨é€šç”¨è¿ç§»
          await migrateGenericTable(table, rows)
        }
        
        totalMigrated += rows.length
        console.log(`  âœ… å®Œæˆ`)
        
      } catch (error: any) {
        if (error.message?.includes('no such table')) {
          console.log(`  âš ï¸  è¡¨ ${table} ä¸å­˜åœ¨ï¼Œè·³è¿‡`)
        } else {
          console.warn(`  âŒ è¡¨ ${table} è¿ç§»å¤±è´¥:`, error.message)
        }
      }
    }
    
    console.log(`\nðŸŽ‰ è¿ç§»å®Œæˆï¼å…±è¿ç§» ${totalMigrated} æ¡è®°å½•`)
    
  } catch (error) {
    console.error('âŒ è¿ç§»å¤±è´¥:', error)
    throw error
  } finally {
    await postgresDb.$disconnect()
  }
}

async function migrateProducts(rows: any[]) {
  for (const product of rows) {
    let sellingPoints: any = []
    let painPoints: any = null
    
    try {
      if (product.sellingPoints) {
        sellingPoints = JSON.parse(product.sellingPoints)
      }
    } catch (e) {
      sellingPoints = []
    }
    
    try {
      if (product.painPoints) {
        painPoints = JSON.parse(product.painPoints)
      }
    } catch (e) {
      painPoints = null
    }
    
    await postgresDb.product.upsert({
      where: { id: product.id },
      create: {
        id: product.id,
        name: product.name,
        description: product.description || '',
        category: product.category,
        subcategory: product.subcategory,
        sellingPoints: sellingPoints,
        skuImages: product.skuImages || '[]',
        targetCountries: product.targetCountries || '[]',
        source: product.source || 'manual',
        sourceUserId: product.sourceUserId,
        isUserGenerated: Boolean(product.isUserGenerated),
        needsReview: Boolean(product.needsReview),
        lastUserUpdate: product.lastUserUpdate ? new Date(product.lastUserUpdate) : null,
        createdAt: new Date(product.createdAt),
        updatedAt: new Date(product.updatedAt),
        painPoints: painPoints,
        painPointsLastUpdate: product.painPointsLastUpdate ? new Date(product.painPointsLastUpdate) : null,
        painPointsSource: product.painPointsSource
      },
      update: {
        name: product.name,
        sellingPoints: sellingPoints,
        painPoints: painPoints,
        updatedAt: new Date(product.updatedAt)
      }
    })
  }
}

async function migrateGenericTable(tableName: string, rows: any[]) {
  // ä½¿ç”¨åŽŸå§‹ SQL æ’å…¥æ•°æ®ï¼ˆé€šç”¨æ–¹æ³•ï¼‰
  for (const row of rows) {
    // è½¬æ¢å¸ƒå°”å€¼
    const processedRow = Object.fromEntries(
      Object.entries(row).map(([key, value]) => {
        if (typeof value === 'number' && (value === 0 || value === 1)) {
          // æ£€æŸ¥å­—æ®µåæ˜¯å¦åƒå¸ƒå°”å­—æ®µ
          if (key.startsWith('is') || key.startsWith('has') || key.includes('Active') || key.includes('Review')) {
            return [key, Boolean(value)]
          }
        }
        return [key, value]
      })
    )
    
    try {
      await (postgresDb as any)[tableName].upsert({
        where: { id: row.id },
        create: processedRow,
        update: processedRow
      })
    } catch (e: any) {
      // å¦‚æžœè¡¨ä¸å­˜åœ¨å¯¹åº”çš„ Prisma æ¨¡åž‹ï¼Œä½¿ç”¨åŽŸå§‹ SQL
      console.log(`    ä½¿ç”¨åŽŸå§‹SQLæ’å…¥ ${tableName}`)
    }
  }
}

migrateAllData()
  .then(() => process.exit(0))
  .catch(() => process.exit(1))

